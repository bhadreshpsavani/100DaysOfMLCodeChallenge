Day2 : 15th April 2019

- python lib called OS is used to make folder and file handling related operations,

- matplotlib.image is used for image related operations


Day3: 16th April 2019

Canny Edge Detection algorithm
- edges = cv2.Canny(gray, low_threshold, high_threshold)
The John Canny recommended low_threshold to high_threshold ratio to be 1:2, 1:3


Hough Transformation: 
- a line in image space corresponds to a point in Hough space, A point in image space describes a line in Hough space

- Two points in image space correspond to two lines in Hough Space. Not only that, but these lines must intersect

we have two intersecting lines in Hough Space. How would you represent their intersection at the point (m0, b0) in image space?
- The intersection point at (m0, b0) represents the line y = m0x + b0 in image space and it must be the line that passes through both points!

lines=cv2.HoughLinesP(masked_edges, rho, theta, threshold, np.array([]),min_line_length,max_line_gap)

Day4: 23rd April 2019

Camera don't create perfect images some of the part at the edge gets stratched or schewed.

Why is it important to correct for image distortion?
1. Distortion can change the apparent size of an object in an image.
2. Distortion can change the apparent shape of an object in an image.
3. Distortion can cause an object's appearance to change depending on where it is in the field of view.
4. Distortion can make objects appear closer or farther away than they actually are.

Types of Distortion in the camera:
  1. Radial Distortion 
  2. Tangential Distortion
  
Chessboard can be used to calibrate camera image to make it undistorted.

cv2.findChessboardCorners() :  The function attempts to determine whether the input image is a view of the chessboard pattern and locate the internal chessboard corners. The function returns a non-zero value if all of the corners are found and they are placed in a certain order (row by row, left to right in every row). Otherwise, if the function fails to find all the corners or reorder them, it returns 0.
ret, corners = cv2.findChessboardCorners(gray, (8,6), None)

cv2.drawChessboardCorners() : The function draws individual chessboard corners detected either as red circles if the board was not found, or as colored corners connected with lines if the board was found.
img = cv2.drawChessboardCorners(img, (8,6), corners, ret)

cv2.calibrateCamera() : It returns the camera matrix, distortion coefficients, rotation and translation vectors etc
ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1],None,None)

cv2.undistort() : dst = cv2.undistort(img, mtx, dist, None, mtx)

Day5: 24th April 2019

Calculating Lane Curvature : 

Self-driving cars need to be told the correct steering angle to turn, left or right. You can calculate this angle if you know a few things about the speed and dynamics of the car and how much the lane is curving.

One way to calculate the curvature of a lane line, is to fit a 2nd degree polynomial to that line, and from this you can easily extract useful information.

For a lane line that is close to vertical, you can fit a line using this formula: f(y) = Ay^2 + By + C, where A, B, and C are coefficients.

A gives you the curvature of the lane line, B gives you the heading or direction that the line is pointing, and C gives you the position of the line based on how far away it is from the very left of an image (y = 0).

Perspective transform

A perspective transform maps the points in a given image to different, desired, image points with a new perspective. The perspective transform you’ll be most interested in is a bird’s-eye view transform that let’s us view a lane from above; this will be useful for calculating the lane curvature later on. Aside from creating a bird’s eye view representation of an image, a perspective transform can also be used for all kinds of different view points.

- Four Points are enough to define linear tranformation from one prospective to another.

Compute the perspective transform, M, given source and destination points:
M = cv2.getPerspectiveTransform(src, dst)

Compute the inverse perspective transform:
Minv = cv2.getPerspectiveTransform(dst, src)

Warp an image using the perspective transform, M:
warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)

Camera Calibration: To compute Transformatuon Between 3D object points in  the world and 2D image points.

Distortion Correction: To ensure that geometric shape of object is represented  consistently, no matter where they appear in the image.

Prespective Transformation: To transform an image such that we are affectively viewing object from a different angle or direction.

Day6: 25th April 2019
Sobels Filter in x and y direction:
    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0)
    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1)

Take the absolute value of the derivative or gradient
    abs_sobelx = np.absolute(sobelx)

Convert the absolute value image to 8-bit:
    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))

Note: It's not entirely necessary to convert to 8-bit (range from 0 to 255) but in practice, it can be useful in the event that you've written a function to apply a particular threshold, and you want it to work the same on input images of different scales, like jpg vs. png. You could just as well choose a different standard range of values, like 0 to 1 etc.

The direction of the gradient is simply the inverse tangent (arctangent) of the yy gradient divided by the xx gradient:
arctan(sobel_y/sobel_x)
