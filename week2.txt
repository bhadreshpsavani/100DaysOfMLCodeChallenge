Day1: 21st March 2019

I learn that we can make OCR based model for single line of text using Keras and TensorFlow.

*Conectionist Temporal Classification (CTC) Loss function : Applied to identified word by removing
    words and white spaces

We can make OCR based model for entire text consist of multiple line, for that we need to do some Preprossessing

DIA(Document Image Analysis): 
                            1. Image Segmentation
                            2. word Extraction
                            3. Text Recongnition using OCR 
                            4. Error reduction of words using Language model or Dictionary APIs

3. Text Recongnition using OCR :
    2 methods:
        1. LSTM
        2. Uniform Segmentation

findContours function of opencv

Line Normalization using 'ocrolib':
    'https://github.com/tmbdev/ocropy/blob/master/doc/line-normalization.ipynb'

*To avoid network overfitting we stopped the training process several times and 
continued training the network with the new dataset

Resources:
'https://dzone.com/articles/using-ocr-for-receipt-recognition';

Day2: 22 march 2019

started Watching videos related to using python for AI.

wanted to learn libraries like 1. numpy: for array manipulation
                               2. Pandas: data Manipulation and Analysis
                               3. scikit: data Visulization
                               4. python: facebook lib for deep learning
                               
Day3: 24-03-2019

Pandas: 
- Dataframe is a heterogeneous object and hence are able to store different datatypes together

Day6: 27-03-2019

supervised learning: the user provides the algorithm with pairs of inputs and desired outputs,
and the algorithm finds a way to produce the desired output given an input

unsupervised learning:
only the input data is known, and no known output data is given to the algorithm

feature extraction or feature engineering: building a good representation of your data

k-Nearest Neighbors Algorithm:

- To make a prediction for a new data point, the algorithm finds the point in the training set that is closest to the new point 
- The k in k-nearest neighbors signifies that instead of using only the closest neighbor to the new data point, we can consider any fixed number k of neighbors in the training.

*  scikit-learn always expects two-dimensional arrays for the data. 

-  The fit, predict, and score methods are the common interface to supervised models in scikit-learn
