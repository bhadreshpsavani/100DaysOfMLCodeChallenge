Day1: 29 mar 2019

Binary Classifier for multiclass problem,

To make a prediction, all binary classifiers are run on a test point. The classifier that has the highest score on its
single class “wins,” and this class label is returned as the prediction.

Decision Tree:

Random Forest: uses two algorithms to make each tree different from each other
        1. Bootstrap sampling
        2. feature selection
        
Critical feature in random forest:

  max_feature parameter: a high max_features means that the trees in the random forest will be quite similar, and they will be
                able to fit the data easily, using the most distinctive features.
                
                         A low max_features means that the trees in the random forest will be quite different, and that each tree
                might need to be very deep in order to fit the data well.

n_estimators: Higher is better

it’s a good rule of thumb to use the default values:  max_features=sqrt(n_features)  for classification and 
                                                      max_features=log2(n_features) for regression

To make a prediction using the random forest, the algorithm first makes a prediction for every tree in the forest. For regression, we can average these results to get our final prediction. For classification, a “soft voting” strategy is used. This means each algorithm makes a  “soft” prediction, providing a probability for each possible output

Gradient boosted regression trees (gradient boosting machines): 1. learning_rate
                                                                2. n_estimartors
                                                    
                                                    
Support Vector Machines: 

Day2: 30 Mar 2019

Deep Learning:

MultiLayerPerceptons(MLP): After computing a weighted sum for each hidden unit, a nonlinear function is applied to the result—usually the rectifying nonlinearity (also known as rectified linear unit or relu) or the tangens hyperbolicus (tanh)

* The relu cuts off values below zero,
* tanh saturates to –1 for low input values and +1 for high input values.

        it have regularization parameter alpha if it is higher then model is more general and if low then model is complex or overfitting
        
- Neural networks—particularly the large and powerful ones—often take a long time to train. 
- They also require careful preprocessing of the data.
- Similarly to SVMs, they work best with “homogeneous” data, where all the features have similar meanings. 
- For data that has very different kinds of features, tree-based models might work better. 

* fit Resets a Model: 
An important property of scikit-learn models is that calling fit will always reset everything a model previously learned. So if you
build a model on one dataset, and then call fit again on a different dataset, the model will “forget” everything it learned from the first dataset.

There is also the question of how to learn the model, or the algorithm that is used for learning the parameters, which is set using the algorithm parameter: Default Adam, l-bfgs, sgd

scikit-learn has ability of classifiers to provide uncertainty estimates of predictions.

scikit-learn that can be used to obtain uncertainty estimates from classifiers: decision_function and predict_proba

predict_proba and decision_function always have shape (n_samples, n_classes)—apart from decision_function in the special binary case. In the binary case, decision_function only has one column, corresponding to the “positive” class classes_[1]

************************Which Algorithm Should We use***********************

Nearest neighbors: For small datasets, good as a baseline, easy to explain.

Linear models: Go-to as a first algorithm to try, good for very large datasets, good for very highdimensional data.

Naive Bayes: Only for classification. Even faster than linear models, good for very large datasets and high-dimensional data. Often less accurate than linear models.

Decision trees: Very fast, don’t need scaling of the data, can be visualized and easily explained.

Random forests: Nearly always perform better than a single decision tree, very robust and powerful. Don’t need scaling of data. Not good for very high-dimensional sparse data.

Gradient boosted decision trees: Often slightly more accurate than random forests. Slower to train but faster to predict than random forests, and smaller in memory. Need more parameter tun‐ing than random forests.

**********************Unsupervised Learning**********************************

Unsupervised transformations of a dataset are algorithms that create a new representation of the data which might be easier for humans or other machine learning algorithms to understand compared to the original representation of the data.

Different Scaler for Preprocessing:
        1. StandardScaler,
        2. RobustScaler,
        3. MinMaxScaler,
        4. Normalizer
   
Other Preprocessing Algorithms:
        1. Principal Component Analysis (PCA),
        2. Non-negative Matrix Factorization (NMF),
        3. t-SNE.

Principal component analysis is a method that rotates the dataset in a way such that the rotated features are statistically uncorrelated. Using PCA, we can capture the main interactions and get a slightly more complete picture. We can find the first two principal components, and visualize the data in this new two-dimensional space with a single scatter plot. The principal components correspond to directions in the original data, so they are combinations of the original features.

PCA can be used for feature extraction of images. PCA finds the optimum directions in terms of reconstruction.

non-negative matrix factorization (NMF), which is commonly used for feature extraction, feature extraction we want both the components and the coefficients to be greater than or equal to zero
NMF is usually not used for its ability to reconstruct or encode data, but rather for finding interesting patterns within the data.

manifold learning algorithms: class of algorithms for visualization

t-SNE, which is commonly used for visualization using two-dimensional scatter plots. The idea behind t-SNE is to find a two-dimensional representation of the data that preserves the distances between points as best as possible.


----------------------------------------------------------------------------------------------------------------------------------------

Day3: 2 April 2019

-------------------------------------------------Model Evaluation and Improvement------------------------------------------------------

Cross-validation is a statistical method of evaluating generalization performance that is more stable and thorough than using a split into a training and a test set

"It is important to keep in mind that cross-validation is not a way to build a model that can be applied to new data. Cross-validation
does not return a model. When calling cross_val_score, multiple models are built internally, but the purpose of cross-validation is
only to evaluate how well a given algorithm will generalize when trained on a specific dataset."

k-fold cross-validation:
The main disadvantage of cross-validation is increased computational cost

Stratified k-Fold Cross-Validation:In stratified cross-validation, we split the data such that the proportions between classes are the same in each fold as they are in the whole dataset

It is usually a good idea to use stratified k-fold cross-validation instead of k-fold cross-validation to evaluate a classifier, because it results in more reliable estimates of generalization performance. 

regression, scikit-learn uses the standard k-fold cross-validation by default.

Leave-one-out cross-validation: This can be very time consuming, particularly for large datasets, but sometimes provides better esti‐
mates on small datasets:

shuffle-split cross-validation: allows for control over the number of iterations independently of the training and test sizes.
StratifiedShuffleSplit cross-validation

Cross-validation with groups:The groups array here indicates groups in the data that should not be split when creating the training and testsets, and should not be confused with the class label


*******************************Grid Search*******************************

we have three sets: 
1. the training set to build the model, 
2. the validation (or development) set to select the parameters of the model, and 
3. the test set to evaluate the performance of the selected parameters

After selecting the best parameters using the validation set, we can rebuild a model using the parameter settings we found, but now training on both the training data and the validation data

scikit-learn provides the GridSearchCV class, which implements it in the form of an estimator

grid_search.cv_results_ : Detailed parameters
grid_search.best_estimator_ : best parameters trained

cross_val_score, GridSearchCV uses stratified k-fold cross-validation
by default for classification, and k-fold cross-validation for regression.

Day4: 4th April 2019

One hot encoding: most common way to represent categorical variables is using the one-hotencoding or one-out-of-N encoding, also known as dummy variables

------------------------------------Clustering -----------------------------------------

clustering is the task of partitioning the dataset into groups, called clusters. The goal is to split up the data in such a way that points within a single cluster are very similar and points in different clusters are different. 

Clustering Algorithms:
1. Kmeans,
2. Agglomerative,
3. DBSCAN(Density Based Spatial Clustring Application with Noise)


#counts How often each target appearce
count= np.bincount(people.target)
